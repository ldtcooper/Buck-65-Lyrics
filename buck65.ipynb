{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd00ade51d2f248a4db4c8713574dd01ddbcf6805a2f9b7c250527c832b53a9f4a1",
   "display_name": "Python 3.9.4 64-bit ('buck65': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# INTRO\n",
    "Ever since coming across [Matt Daniel's Rapper Vocabulary Chart](https://pudding.cool/projects/vocabulary/index.html), I've been interested in how one of my favorite rappers -- Buck 65 -- would place on there. To find that, I'll be getting as many lyrics as I can from LyricsGenius to get up to 35,000 lyrics in accordance with the original methodology:\n",
    "\n",
    "```\n",
    "35,000 words covers 3-5 studio albums and EPs. I included mixtapes if the artist was just short of the 35,000 words. Quite a few rappers don’t have enough official material to be included (e.g., Biggie, Kendrick Lamar). As a benchmark, I included data points for Shakespeare and Herman Melville, using the same approach (35,000 words across several plays for Shakespeare, first 35,000 of Moby Dick).\n",
    "\n",
    "I used a research methodology called token analysis to determine each artist’s vocabulary. Each word is counted once, so pimps, pimp, pimping, and pimpin are four unique words. To avoid issues with apostrophes (e.g., pimpin’ vs. pimpin), they’re removed from the dataset. It still isn’t perfect. Hip hop is full of slang that is hard to transcribe (e.g., shorty vs. shawty), compound words (e.g., king shit), featured vocalists, and repetitive choruses.\n",
    "```\n",
    "\n",
    "With those lyrics, I'll be cleaning the data to remove apostrophes and (possibly) other special characters, and then using NLTK to break the lyrics into tokens and count the number of individual words."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lyricsgenius\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "secrets_file = open('secrets.json')\n",
    "secrets = json.load(secrets_file)\n",
    "secrets_file.close()\n",
    "\n",
    "def make_initial_dataframe(json_file):\n",
    "    f = open(json_file)\n",
    "    buck_json = json.load(f)\n",
    "    songs = pd.DataFrame(buck_json['songs'])\n",
    "\n",
    "    unneeded_cols = list(songs.columns.values)\n",
    "\n",
    "    # we only need these three values, so we drop the rest\n",
    "    unneeded_cols.remove('lyrics')\n",
    "    unneeded_cols.remove('title')\n",
    "    unneeded_cols.remove('release_date')\n",
    "    unneeded_cols.remove('album')\n",
    "\n",
    "    songs = songs.drop(unneeded_cols, axis=1)\n",
    "    songs.head()\n",
    "    return songs\n",
    "\n",
    "def find_album(album):\n",
    "    return album['name']\n",
    "\n",
    "def format_albums(songs):\n",
    "    albums = songs['album']\n",
    "    songs['album'] = albums.map(find_album, na_action='ignore')\n",
    "\n",
    "    songs.head()\n",
    "    return songs\n",
    "\n",
    "def clean_lyrics(songs):\n",
    "    # remove remixes\n",
    "    remixes = songs['title'].str.contains('([rR]emix\\)|\\[Acoustic Version\\])')\n",
    "    songs = songs[~remixes]\n",
    "\n",
    "    # remove newlines\n",
    "    songs['lyrics'] = songs['lyrics'].str.replace('[\\n\\t]', ' ')\n",
    "    # replace hyphens/dashes with spaces\n",
    "    songs['lyrics'] = songs['lyrics'].str.replace('[-–—]', ' ')\n",
    "    # remove all other punctuation\n",
    "    songs['lyrics'] = songs['lyrics'].str.replace('[^a-zA-Z0-9 ]', '')\n",
    "\n",
    "    songs['lyrics'] = songs['lyrics'].str.lower()\n",
    "    return songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up genius api access\n",
    "genius = lyricsgenius.Genius(secrets['CLIENT_ACCESS_TOKEN'])\n",
    "genius.remove_section_headers = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this only needs to be run if Lyrics_Buck65.json doesn't exist\n",
    "# it will also take a while\n",
    "# buck = genius.search_artist(\"Buck 65\")\n",
    "# buck.save_lyrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn JSON into pandas dataframe\n",
    "songs = make_initial_dataframe(\"Lyrics_Buck65.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the album name from the JSON \n",
    "songs = format_albums(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     title release_date  \\\n",
       "81             Who By Fire         None   \n",
       "27         Cold Steel Drum   2011-01-01   \n",
       "31          Zombie Delight   2011-02-07   \n",
       "54            She Said Yes   2011-01-01   \n",
       "59                     BCC   2011-01-01   \n",
       "62     Tears Of Your Heart   2011-02-07   \n",
       "76          Final Approach   2011-01-01   \n",
       "8           Paper Airplane   2011-01-01   \n",
       "25                Gee Whiz         None   \n",
       "5    Whispers Of The Waves   2011-01-01   \n",
       "101  Superstars Don’t Love         None   \n",
       "95                    Stop   2011-01-01   \n",
       "107              Joey Bats         None   \n",
       "108                Dolores   2011-01-01   \n",
       "127                 Stupid         None   \n",
       "163            Highway 101         None   \n",
       "145                January   2004-01-01   \n",
       "9             Blood, Pt. 2   2009-02-16   \n",
       "153             Feels Like         None   \n",
       "129            Why So Sad?   2008-01-01   \n",
       "\n",
       "                                                 album  \\\n",
       "81                                        20 Odd Years   \n",
       "27                                        20 Odd Years   \n",
       "31                                        20 Odd Years   \n",
       "54                                        20 Odd Years   \n",
       "59                                        20 Odd Years   \n",
       "62                                        20 Odd Years   \n",
       "76                                        20 Odd Years   \n",
       "8                                         20 Odd Years   \n",
       "25                                        20 Odd Years   \n",
       "5                                         20 Odd Years   \n",
       "101                                       20 Odd Years   \n",
       "95                                        20 Odd Years   \n",
       "107                20 Odd Years: Volume 4 - Ostranenie   \n",
       "108                20 Odd Years: Volume 4 - Ostranenie   \n",
       "127                                     Boy-Girl Fight   \n",
       "163                                     Boy-Girl Fight   \n",
       "145  Climbing Up a Mountain With a Basket Full of F...   \n",
       "9                                   Dark Was the Night   \n",
       "153                                           Dirtbike   \n",
       "129                                         Dirtbike 3   \n",
       "\n",
       "                                                lyrics  \n",
       "81   And who by fire?\\nWho by water?\\nWho in the su...  \n",
       "27   I lay down for you, in black and blue\\nLife he...  \n",
       "31   Zombie Delight Zombie Delight\\nZombies are com...  \n",
       "54   She wrote back, too alone\\nA single pair of sh...  \n",
       "59   BCC the ADD\\nWe don't have much time you see\\n...  \n",
       "62   (French singing)\\n\\nAge is beauty, bewildered ...  \n",
       "76   The sun is always shining bright, at thirty th...  \n",
       "8    Down by the lake you saw me\\nAnd you knew I wa...  \n",
       "25   Tell me what is it is, Gee Whiz, I don't think...  \n",
       "5    I am the deck, you are the sea...*\\nI am the l...  \n",
       "101  Michael Jackson died today\\nCycle's action, hi...  \n",
       "95   Stop you need to listen\\nJust let me show you ...  \n",
       "107  Jose Baustia, also known as Joey Bats\\nKnow th...  \n",
       "108  All the world was black and white\\nJust a soun...  \n",
       "127  Get stupid y'all\\n\\nLimited Scream\\nMen and wo...  \n",
       "163  Snakes in the outerfield, infield vipers\\nI re...  \n",
       "145  Now I could hear the coyotes when I laid in a ...  \n",
       "9    You're not bloody swab paradise\\nYou're golden...  \n",
       "153  She found the lost boy, eyes that are crying c...  \n",
       "129  Under the bed, on the floor, through the roof\\...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>release_date</th>\n      <th>album</th>\n      <th>lyrics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>81</th>\n      <td>Who By Fire</td>\n      <td>None</td>\n      <td>20 Odd Years</td>\n      <td>And who by fire?\\nWho by water?\\nWho in the su...</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Cold Steel Drum</td>\n      <td>2011-01-01</td>\n      <td>20 Odd Years</td>\n      <td>I lay down for you, in black and blue\\nLife he...</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Zombie Delight</td>\n      <td>2011-02-07</td>\n      <td>20 Odd Years</td>\n      <td>Zombie Delight Zombie Delight\\nZombies are com...</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>She Said Yes</td>\n      <td>2011-01-01</td>\n      <td>20 Odd Years</td>\n      <td>She wrote back, too alone\\nA single pair of sh...</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>BCC</td>\n      <td>2011-01-01</td>\n      <td>20 Odd Years</td>\n      <td>BCC the ADD\\nWe don't have much time you see\\n...</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>Tears Of Your Heart</td>\n      <td>2011-02-07</td>\n      <td>20 Odd Years</td>\n      <td>(French singing)\\n\\nAge is beauty, bewildered ...</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>Final Approach</td>\n      <td>2011-01-01</td>\n      <td>20 Odd Years</td>\n      <td>The sun is always shining bright, at thirty th...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Paper Airplane</td>\n      <td>2011-01-01</td>\n      <td>20 Odd Years</td>\n      <td>Down by the lake you saw me\\nAnd you knew I wa...</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Gee Whiz</td>\n      <td>None</td>\n      <td>20 Odd Years</td>\n      <td>Tell me what is it is, Gee Whiz, I don't think...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Whispers Of The Waves</td>\n      <td>2011-01-01</td>\n      <td>20 Odd Years</td>\n      <td>I am the deck, you are the sea...*\\nI am the l...</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>Superstars Don’t Love</td>\n      <td>None</td>\n      <td>20 Odd Years</td>\n      <td>Michael Jackson died today\\nCycle's action, hi...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>Stop</td>\n      <td>2011-01-01</td>\n      <td>20 Odd Years</td>\n      <td>Stop you need to listen\\nJust let me show you ...</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>Joey Bats</td>\n      <td>None</td>\n      <td>20 Odd Years: Volume 4 - Ostranenie</td>\n      <td>Jose Baustia, also known as Joey Bats\\nKnow th...</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>Dolores</td>\n      <td>2011-01-01</td>\n      <td>20 Odd Years: Volume 4 - Ostranenie</td>\n      <td>All the world was black and white\\nJust a soun...</td>\n    </tr>\n    <tr>\n      <th>127</th>\n      <td>Stupid</td>\n      <td>None</td>\n      <td>Boy-Girl Fight</td>\n      <td>Get stupid y'all\\n\\nLimited Scream\\nMen and wo...</td>\n    </tr>\n    <tr>\n      <th>163</th>\n      <td>Highway 101</td>\n      <td>None</td>\n      <td>Boy-Girl Fight</td>\n      <td>Snakes in the outerfield, infield vipers\\nI re...</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>January</td>\n      <td>2004-01-01</td>\n      <td>Climbing Up a Mountain With a Basket Full of F...</td>\n      <td>Now I could hear the coyotes when I laid in a ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Blood, Pt. 2</td>\n      <td>2009-02-16</td>\n      <td>Dark Was the Night</td>\n      <td>You're not bloody swab paradise\\nYou're golden...</td>\n    </tr>\n    <tr>\n      <th>153</th>\n      <td>Feels Like</td>\n      <td>None</td>\n      <td>Dirtbike</td>\n      <td>She found the lost boy, eyes that are crying c...</td>\n    </tr>\n    <tr>\n      <th>129</th>\n      <td>Why So Sad?</td>\n      <td>2008-01-01</td>\n      <td>Dirtbike 3</td>\n      <td>Under the bed, on the floor, through the roof\\...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "songs.sort_values(by='album', inplace=True)\n",
    "songs.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/root/miniconda3/envs/buck65/lib/python3.9/site-packages/pandas/core/strings/accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n  return func(self, *args, **kwargs)\n<ipython-input-1-8f6cb536841b>:42: FutureWarning: The default value of regex will change from True to False in a future version.\n  songs['lyrics'] = songs['lyrics'].str.replace('[\\n\\t]', ' ')\n<ipython-input-1-8f6cb536841b>:42: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  songs['lyrics'] = songs['lyrics'].str.replace('[\\n\\t]', ' ')\n<ipython-input-1-8f6cb536841b>:44: FutureWarning: The default value of regex will change from True to False in a future version.\n  songs['lyrics'] = songs['lyrics'].str.replace('[-–—]', ' ')\n<ipython-input-1-8f6cb536841b>:44: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  songs['lyrics'] = songs['lyrics'].str.replace('[-–—]', ' ')\n<ipython-input-1-8f6cb536841b>:46: FutureWarning: The default value of regex will change from True to False in a future version.\n  songs['lyrics'] = songs['lyrics'].str.replace('[^a-zA-Z0-9 ]', '')\n<ipython-input-1-8f6cb536841b>:46: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  songs['lyrics'] = songs['lyrics'].str.replace('[^a-zA-Z0-9 ]', '')\n<ipython-input-1-8f6cb536841b>:48: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  songs['lyrics'] = songs['lyrics'].str.lower()\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "297778"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# clean data\n",
    "songs = clean_lyrics(songs)\n",
    "\n",
    "\n",
    "# save\n",
    "songs.to_csv('buck65.tsv', sep=\"\\t\", index=False)\n",
    "\n",
    "songs['lyrics'].str.len().sum()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "# Rundown\n",
    "\n",
    "So far, we have gathered, sorted, and cleaned all of the lyrics from Buck 65's Genius entry. We can see that we have 297,778 individual lyrics across 163 songs. The first step then is to narrow that down to the 35,000 used in the original project. More specifically, we need to get the (chronologically) first 35,000 words. To do that, we'll need a list of his albums, which I've gotten from [this Wikipedia article](https://en.wikipedia.org/wiki/Buck_65_discography). The most relevant part of that article is pasted below:\n",
    "\n",
    "```\n",
    "Studio albums\n",
    "Buck 65\n",
    "\n",
    "Game Tight (1994)\n",
    "Year Zero (1996)\n",
    "Weirdo Magnet (1996)\n",
    "Language Arts (1996)\n",
    "Vertex (1998)\n",
    "Man Overboard (Anticon, 2001)\n",
    "Synesthesia (Endemik, 2001)\n",
    "Square (WEA, 2002)\n",
    "Talkin' Honky Blues (WEA, 2003)\n",
    "Secret House Against the World (WEA, 2005)\n",
    "Situation (Strange Famous, 2007)\n",
    "20 Odd Years (WEA, 2011)\n",
    "Laundromat Boogie (2014)\n",
    "Neverlove (2014)\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "songs = pd.read_csv('buck65.tsv', sep=\"\\t\", keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            title release_date          album  \\\n",
       "150      Untitled               Weirdo Magnet   \n",
       "38   Pubic’s Tube               Language Arts   \n",
       "37     Bush Pilot               Language Arts   \n",
       "36     Totem Pole   1997-01-01  Language Arts   \n",
       "35      Seventeen               Language Arts   \n",
       "\n",
       "                                                lyrics  ordered_album  \n",
       "150   yes the actual name of the song is untitled i...  Weirdo Magnet  \n",
       "38   stinkin rich is x rated guess whos squirtin co...  Language Arts  \n",
       "37   we should take a break from the computers and ...  Language Arts  \n",
       "36   we dont need to watch tv tonight this is for u...  Language Arts  \n",
       "35   this ones goin out to all of those that dont k...  Language Arts  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>release_date</th>\n      <th>album</th>\n      <th>lyrics</th>\n      <th>ordered_album</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>150</th>\n      <td>Untitled</td>\n      <td></td>\n      <td>Weirdo Magnet</td>\n      <td>yes the actual name of the song is untitled i...</td>\n      <td>Weirdo Magnet</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>Pubic’s Tube</td>\n      <td></td>\n      <td>Language Arts</td>\n      <td>stinkin rich is x rated guess whos squirtin co...</td>\n      <td>Language Arts</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Bush Pilot</td>\n      <td></td>\n      <td>Language Arts</td>\n      <td>we should take a break from the computers and ...</td>\n      <td>Language Arts</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Totem Pole</td>\n      <td>1997-01-01</td>\n      <td>Language Arts</td>\n      <td>we dont need to watch tv tonight this is for u...</td>\n      <td>Language Arts</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Seventeen</td>\n      <td></td>\n      <td>Language Arts</td>\n      <td>this ones goin out to all of those that dont k...</td>\n      <td>Language Arts</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# sort albums by album release\n",
    "albums = [\n",
    "    'Game Tight',\n",
    "    'Year Zero',\n",
    "    'Weirdo Magnet',\n",
    "    'Language Arts',\n",
    "    'Vertex',\n",
    "    'Man Overboard',\n",
    "    'Synesthesia',\n",
    "    'Square',\n",
    "    'Talkin\\' Honky Blues',\n",
    "    'Secret House Against the World',\n",
    "    'Situation',\n",
    "    '20 Odd Years',\n",
    "    'Laundromat Boogie',\n",
    "    'Neverlove'\n",
    "]\n",
    "\n",
    "songs['ordered_album'] = pd.Categorical(\n",
    "    songs['album'], \n",
    "    categories=albums, \n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "songs = songs.sort_values(by='ordered_album')\n",
    "\n",
    "songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6351"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "def get_unique_lyrics(tokens):\n",
    "    return len(set(tokens))\n",
    "\n",
    "def tokenize_lyrics(songs):\n",
    "    lyrics = songs['lyrics']\n",
    "    lyric_string = lyrics.str.cat()\n",
    "    return nltk.word_tokenize(lyric_string)\n",
    "\n",
    "lyric_tokens = tokenize_lyrics(songs)\n",
    "# get unique words in first 35,000 lyrics\n",
    "limited_tokens = lyric_tokens[:34999]\n",
    "get_unique_lyrics(limited_tokens)\n",
    "\n"
   ]
  },
  {
   "source": [
    "# First Conclusion\n",
    "\n",
    "The above cell gives us Buck 65's vocabulary according to Daniel's first 35,000 word methodology: 6,351 unique words. This puts him in a close 5th place behind GZA's 6,390 unique words, but comfortably ahead of Wu-Tang Clan's 6,196 unique words. While this is a good result, I want to see how sensitive it is to changes in the sample. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#all lyrics\n",
    "print(get_unique_lyrics(lyric_tokens))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8457\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6579\n"
     ]
    }
   ],
   "source": [
    "# last words\n",
    "last_tokens = lyric_tokens[-35000:]\n",
    "print(get_unique_lyrics(last_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[6493, 6505, 6521, 6524, 6525, 6526, 6546, 6546, 6554, 6568]\n6530.8\n"
     ]
    }
   ],
   "source": [
    "# random samplings\n",
    "from random import sample\n",
    "from statistics import mean\n",
    "\n",
    "counter = 0\n",
    "results = []\n",
    "while counter < 10:\n",
    "    lyric_sample = sample(lyric_tokens, 35000)\n",
    "    uniques = get_unique_lyrics(lyric_sample)\n",
    "    results.append(uniques)\n",
    "    counter += 1\n",
    "\n",
    "print(sorted(results))\n",
    "print(mean(results))"
   ]
  },
  {
   "source": [
    "# Second Conclusion\n",
    "\n",
    "When using his whole corpus of 297,778 words, we find 8,456 unique ones. Using his last 35,000 words gets us 6,580 unique words, implying an increase in vocabulary over time. Finally, using a series of random samplings of 35,000 words, we get results that tend to average out just over 6,500, but can range from the high 6,400s to the low 6,600s.\n",
    "\n",
    "While this is another good result, I have a hypothesis that these numbers will all go up noticably if I include two albums which he recorded as part of a collaboration with DJ Greetings from Tuskan."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Searching for songs by Bike for Three...\n",
      "\n",
      "Changing artist name to 'Bike For Three!'\n",
      "Song 1: \"Lazarus Phenomenon\"\n",
      "Song 2: \"Always I Will Miss You. Always You.\"\n",
      "Song 3: \"There Is Only One Of Us\"\n",
      "Song 4: \"All There Is to Say About Love\"\n",
      "Song 5: \"Sublimation\"\n",
      "Song 6: \"No Idea How\"\n",
      "Song 7: \"You Can Be Everything\"\n",
      "Song 8: \"Nightdriving\"\n",
      "Song 9: \"Heart as Hell\"\n",
      "Song 10: \"Wolf Sister\"\n",
      "Song 11: \"Let’s Never Meet\"\n",
      "Song 12: \"Can Feel Love (anymore)\"\n",
      "Song 13: \"Ethereal Love\"\n",
      "Song 14: \"More Heart Than Brains\"\n",
      "Song 15: \"Full Moon\"\n",
      "Song 16: \"The Departure\"\n",
      "Song 17: \"MC Space\"\n",
      "Song 18: \"Agony\"\n",
      "Song 19: \"One More Time Forever\"\n",
      "Song 20: \"Successful With Heavy Losses\"\n",
      "Song 21: \"The Muse Inside Me\"\n",
      "Song 22: \"First Embrace\"\n",
      "Song 23: \"The Last Romance\"\n",
      "Song 24: \"Ending\"\n",
      "Song 25: \"Intro\"\n",
      "Song 26: \"Beginning\"\n",
      "Done. Found 26 songs.\n",
      "Wrote Lyrics_BikeForThree.json.\n"
     ]
    }
   ],
   "source": [
    "# bike = genius.search_artist(\"Bike for Three!\")\n",
    "# bike.save_lyrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}